{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from random import choice\n",
    "from string import ascii_lowercase\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import datetime\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149\n"
     ]
    }
   ],
   "source": [
    "from assistant import Shop\n",
    "\n",
    "SHOPS_IMPRINTS = '../StaticData/shop_imprints.pickle_bk'\n",
    "\n",
    "shop_vecs = {}\n",
    "shops_imprints = pickle.load(open(SHOPS_IMPRINTS, 'rb'))\n",
    "for shop_imprint, shop in shops_imprints:\n",
    "    shop_vecs[shop.name] = shop_imprint\n",
    "\n",
    "print(len(shop_vecs.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>email</th>\n",
       "      <th>places</th>\n",
       "      <th>times</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-08-26</td>\n",
       "      <td>tebqnkrqnngumcmgijq@yandex.ru</td>\n",
       "      <td>[Accessorize, NIKE, Accessorize, NIKE, NIKE, M...</td>\n",
       "      <td>[01:06, 01:47, 01:54, 02:10, 03:16, 05:33, 07:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-09-03</td>\n",
       "      <td>quweykzbwo@mail.ru</td>\n",
       "      <td>[Mlesna, Mlesna, MANGO, Vans, Vans, MANGO, Van...</td>\n",
       "      <td>[00:20, 00:45, 00:50, 01:44, 02:12, 02:16, 03:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-08-11</td>\n",
       "      <td>cozjjnfuafmasidri@mail.ru</td>\n",
       "      <td>[MANGO, MANGO, MANGO, Calvin Klein Jeans, Calv...</td>\n",
       "      <td>[00:01, 00:26, 00:42, 01:12, 01:24, 01:39, 01:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-08-09</td>\n",
       "      <td>nqyadzvauvachmqrqab@google.com</td>\n",
       "      <td>[Brown Art, THE BODY SHOP, THE BODY SHOP, THE ...</td>\n",
       "      <td>[01:24, 02:47, 03:43, 05:09, 06:22, 07:34, 09:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-08-23</td>\n",
       "      <td>jfxqtsdawd@yandex.ru</td>\n",
       "      <td>[Yves Rocher, Crocs, Crocs, Yves Rocher, Yves ...</td>\n",
       "      <td>[00:34, 00:55, 01:32, 01:48, 02:42, 03:09, 03:...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                           email  \\\n",
       "0  2019-08-26   tebqnkrqnngumcmgijq@yandex.ru   \n",
       "1  2019-09-03              quweykzbwo@mail.ru   \n",
       "2  2019-08-11       cozjjnfuafmasidri@mail.ru   \n",
       "3  2019-08-09  nqyadzvauvachmqrqab@google.com   \n",
       "4  2019-08-23            jfxqtsdawd@yandex.ru   \n",
       "\n",
       "                                              places  \\\n",
       "0  [Accessorize, NIKE, Accessorize, NIKE, NIKE, M...   \n",
       "1  [Mlesna, Mlesna, MANGO, Vans, Vans, MANGO, Van...   \n",
       "2  [MANGO, MANGO, MANGO, Calvin Klein Jeans, Calv...   \n",
       "3  [Brown Art, THE BODY SHOP, THE BODY SHOP, THE ...   \n",
       "4  [Yves Rocher, Crocs, Crocs, Yves Rocher, Yves ...   \n",
       "\n",
       "                                               times  \n",
       "0  [01:06, 01:47, 01:54, 02:10, 03:16, 05:33, 07:...  \n",
       "1  [00:20, 00:45, 00:50, 01:44, 02:12, 02:16, 03:...  \n",
       "2  [00:01, 00:26, 00:42, 01:12, 01:24, 01:39, 01:...  \n",
       "3  [01:24, 02:47, 03:43, 05:09, 06:22, 07:34, 09:...  \n",
       "4  [00:34, 00:55, 01:32, 01:48, 02:42, 03:09, 03:...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class HistoricalPlacesGenerator(object):\n",
    "    SHOPS_CSV = '../StaticData/shops.csv'\n",
    "    \n",
    "    @staticmethod\n",
    "    def generate_string():\n",
    "        n = random.randint(10, 20)\n",
    "        return \"\".join(choice(ascii_lowercase) for i in range(n))\n",
    "    \n",
    "    @staticmethod\n",
    "    def generate_email():\n",
    "        return HistoricalPlacesGenerator.generate_string() + \"@\" + \\\n",
    "            random.choice([\"mail.ru\", \"yandex.ru\", \"google.com\"])\n",
    "    \n",
    "    @staticmethod\n",
    "    def generate_date(start_date=datetime.datetime(2019, 8, 1), random_duration=60):\n",
    "        day_duration = 60 * 60 * 24\n",
    "        time_step = day_duration * random.randint(0, random_duration)\n",
    "        return start_date + datetime.timedelta(0, time_step)\n",
    "    \n",
    "    @staticmethod\n",
    "    def generate_times(date, n):\n",
    "        def generate_time():\n",
    "            start_date = datetime.datetime(2019, 8, 1)\n",
    "            time_step = 60 * random.randint(0, 60 * 24)\n",
    "            return start_date + datetime.timedelta(0, time_step)\n",
    "        return sorted([generate_time() for _ in range(n)])\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_events_count(date):\n",
    "        weekno = datetime.datetime.today().weekday()\n",
    "        if weekno < 5:\n",
    "            count = random.randint(9, 27)\n",
    "        else:\n",
    "            count = random.randint(21, 48)\n",
    "        return count\n",
    "\n",
    "    def __init__(self, nprofiles=1000):\n",
    "        self.character_to_shop = {}\n",
    "        self.profiles = self._generate_profiles(nprofiles)\n",
    "    \n",
    "    def _generate_profiles(self, nprofiles, diff_chars=3):\n",
    "        df = pd.read_csv(self.SHOPS_CSV)[['name', 'searchTags']]\n",
    "        self.character_to_shop = {}\n",
    "        for _, row in df.iterrows():\n",
    "            if not isinstance(row['searchTags'], str):\n",
    "                searchTags = [row['name']]\n",
    "            else:\n",
    "                searchTags = row['searchTags'].split('|')\n",
    "            for tag in searchTags:\n",
    "                self.character_to_shop[tag] = row['name']\n",
    "        characters = list(self.character_to_shop.keys())\n",
    "        return [\n",
    "            {'email': HistoricalPlacesGenerator.generate_email(),\n",
    "             'profile': random.sample(characters, diff_chars)\n",
    "            } for _ in range(nprofiles)]\n",
    "    \n",
    "    def _choose_profile(self):\n",
    "        return random.choice(self.profiles)\n",
    "    \n",
    "    def _generate_places(self):\n",
    "        profile = self._choose_profile()\n",
    "        def generate_place():\n",
    "            char = random.choice(profile['profile'])\n",
    "            return self.character_to_shop[char]\n",
    "        \n",
    "        date = HistoricalPlacesGenerator.generate_date()\n",
    "        places = [generate_place() for _ in range(HistoricalPlacesGenerator.get_events_count(date))]\n",
    "        times = HistoricalPlacesGenerator.generate_times(date, len(places))\n",
    "        return profile, date, places, times\n",
    "\n",
    "    def generate_row(self):\n",
    "        profile, date, places, times = self._generate_places()\n",
    "        return {\n",
    "            'email': profile['email'],\n",
    "            'date': date.strftime(\"%Y-%m-%d\"),\n",
    "            'places': places,\n",
    "            'times': list(map(lambda time: time.strftime(\"%H:%M\"), times))\n",
    "        }\n",
    "\n",
    "    def generate_dataset(self, nrows=10):\n",
    "        rows = [self.generate_row() for _ in range(nrows)]\n",
    "        return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "historical_places_generator = HistoricalPlacesGenerator()\n",
    "df = historical_places_generator.generate_dataset(nrows=10000)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "143"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class PlacesIndexesMapping(object):\n",
    "    # shop_vecs: name -> vector\n",
    "    def __init__(self, df, shop_vecs):\n",
    "        self.n_places = 0\n",
    "        self.place_to_idx = {}\n",
    "        self.idx_to_place = {}\n",
    "        self._make_mapping(df)\n",
    "        self._shop_vecs = shop_vecs\n",
    "    \n",
    "    def _make_mapping(self, df):\n",
    "        for idx, row in df[['places']].iterrows():\n",
    "            places_line = row['places']\n",
    "            for place in places_line:\n",
    "                if place not in self.place_to_idx:\n",
    "                    self.place_to_idx[place] = self.n_places\n",
    "                    self.idx_to_place[self.n_places] = place\n",
    "                    self.n_places += 1\n",
    "\n",
    "indexer = PlacesIndexesMapping(df, shop_vecs)\n",
    "indexer.n_places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    }
   ],
   "source": [
    "class DataInjestor(object):\n",
    "    def __init__(self, df, shop_vecs):\n",
    "        self.indexer = PlacesIndexesMapping(df, shop_vecs)\n",
    "        self._places_lines_idxs = []\n",
    "        self._places_lines_vecs = []\n",
    "        self._prepare_places(df)\n",
    "    \n",
    "    def _prepare_places(self, df):\n",
    "        df_sorted = df.sort_values(by='date')\n",
    "        time_seriess = defaultdict(list)\n",
    "        for _, row in df_sorted.iterrows():\n",
    "            time_seriess[row['email']].append(row['places'])\n",
    "        for email, llst in time_seriess.items():\n",
    "            places_line_idxs = [self.indexer.place_to_idx[x] for y in llst for x in y]\n",
    "            self._places_lines_idxs.append(places_line_idxs)\n",
    "            places_line_vecs = [shop_vecs[x] for y in llst for x in y]\n",
    "            self._places_lines_vecs.append(places_line_vecs)\n",
    "    \n",
    "    def get_size(self):\n",
    "        return self.indexer.n_places\n",
    "    \n",
    "    def sample(self):\n",
    "        history_available = [40, 50]\n",
    "        result = random.choice(self._places_lines_idxs)\n",
    "        if len(result) <= history_available[1]:\n",
    "            return result\n",
    "        drop_left_max = len(result) - history_available[1]\n",
    "        result = result[random.randint(0, drop_left_max):]\n",
    "\n",
    "        chop_idx = random.randint(history_available[0], history_available[1])\n",
    "        result = result[:chop_idx]\n",
    "        return result\n",
    "    \n",
    "    def sample_vec(self):\n",
    "        history_available = [30, 40]\n",
    "        result = random.choice(self._places_lines_vecs)\n",
    "        if len(result) <= history_available[1]:\n",
    "            return result\n",
    "        drop_left_max = len(result) - history_available[1]\n",
    "        result = result[random.randint(0, drop_left_max):]\n",
    "\n",
    "        chop_idx = random.randint(history_available[0], history_available[1])\n",
    "        result = result[:chop_idx]\n",
    "        return result\n",
    "    \n",
    "    def convert_idx_to_place(self, idx):\n",
    "        return self.indexer.idx_to_place[idx]\n",
    "\n",
    "\n",
    "injestor = DataInjestor(df, shop_vecs)\n",
    "print(len(injestor.sample_vec()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inputTensor(vecs):\n",
    "    return torch.tensor(vecs[:-1]).reshape(300, 1, -1)\n",
    "\n",
    "def targetTensor(vecs):\n",
    "    return torch.tensor(vecs[1:]).reshape(300, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, 1)\n",
    "        self.hidden2out = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, inp):\n",
    "        lstm_out, _ = self.lstm(inp)\n",
    "        out = self.hidden2out(lstm_out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomTrainingExample():\n",
    "    sample = injestor.sample_vec()\n",
    "    inp = inputTensor(sample)\n",
    "    out = targetTensor(sample)\n",
    "    return inp, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(rnn, optimizer, criterion, src_tensor, tgt_tensor):\n",
    "    rnn.zero_grad()\n",
    "    loss = 0\n",
    "    \n",
    "    output = rnn(src_tensor.view(src_tensor.size(2), 1, -1))\n",
    "    loss = torch.sqrt(criterion(output, tgt_tensor.reshape(tgt_tensor.size(2), 1, -1)))\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return output, loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2022\n",
      "0.1901\n",
      "0.2014\n",
      "0.0715\n",
      "0.2101\n",
      "0.0210\n",
      "0.2436\n",
      "0.0887\n",
      "0.2039\n",
      "0.2124\n",
      "0.1972\n",
      "0.1048\n",
      "0.2061\n",
      "0.0071\n",
      "0.2015\n",
      "0.0084\n",
      "0.1055\n",
      "0.1986\n",
      "0.0986\n",
      "0.1044\n"
     ]
    }
   ],
   "source": [
    "rnn = RNN(300, 32, 300)\n",
    "\n",
    "learning_rate = 1e-3\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=learning_rate)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "n_iters = 10000\n",
    "print_every = 500\n",
    "plot_every = 500\n",
    "all_losses = []\n",
    "total_loss = 0\n",
    "\n",
    "\n",
    "for iter in range(1, n_iters + 1):\n",
    "    output, loss = train(rnn, optimizer, criterion, *randomTrainingExample())\n",
    "    total_loss += loss\n",
    "\n",
    "    if iter % print_every == 0:\n",
    "        print('%.4f' % (loss))\n",
    "\n",
    "    if iter % plot_every == 0:\n",
    "        all_losses.append(total_loss / plot_every)\n",
    "        total_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest(vec):\n",
    "    distances = []\n",
    "    for shop, vec2 in shop_vecs.items():\n",
    "        distances.append((((vec - vec2)**2).sum(), shop))\n",
    "    return sorted(distances)[1]\n",
    "\n",
    "def predict(src_tensor):\n",
    "    rnn.eval()\n",
    "    output = rnn(src_tensor.view(src_tensor.size(2), 1, -1))\n",
    "    return find_closest(output[0, 0].detach().numpy())\n",
    "\n",
    "vec = inputTensor(injestor.sample_vec())\n",
    "predict(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump model\n",
    "torch.save(rnn.state_dict(), '../StaticData/model.torch')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
